---
aliases:
  - COMP3711 index
  - COMP3711
  - Design and Analysis of algorithms
  - Algorithms
tags:
  - flashcard/active/algo
  - COMP3711
---

# COMP3711
- All the following will be typed by hand after I read and progress through:
  - lecture notes of HKUST COMP3711
  - HKUST COMP3711H materials prepared by professor Arya. 
  - https://amir.goharshady.com/teaching/honors-algorithms 
  - https://amir.goharshady.com/teaching/honors-discrete-math
# Lecture 1
## COMP3711H
## Overview of COMP3711H
What is the course about:
- about something discussed earlier in COMP2711:
  - asymptotics
  - summations
  - recurrences
  - sorting
  - basic graph algorithms (?)
- about algorithm design techniques:
  - [greedy](../../../notes/greedy-algorithms.md)
  - [dynamic programming](../../../notes/dp.md)
  -  augmentation-based methods (for network flow problems) (?)
- first half of the course talks about problems that can be solved efficiently
- second half would be on intractability and NP-hard problems (?)
  - basically problems that no efficient solutions were found
- finally, discuss methods to approximately NP-hard problems


## Algorithm
- what is an algorithm:
  - algorithm refers to a certain sequence computational steps, steps that be programmed, that receives some **inputs** and produces the corresponding desired **outputs** of the problem
## Design
- why do we want to design algorithms and study the art of doing so?
  - To develop efficient algorithms. Here are some common techniques includes:
    - [divide-and-conquer](../../../notes/divide-and-conquer.md)
    - [greedy](../../../notes/greedy-algorithms.md) 
    - [dynamic programming](../../../notes/dp.md)
  - To solve tricky combinatorics problem
### some issues
- we need to be concerned about the _correctness_ and _efficiency_ of algorithms 
## Analysis
- Complexity analysis
  - running time analysis:
    - T(n) : n being the _input size_ here. The worst-case number of steps to count primitive steps: (adding two numbers, multiplying two numbers, comparing two numbers etc.)
  - [Asymptotic analysis](../../../notes/asymptotic_analysis.md):
    - to identify promising solutions 

## Some mental notes on describing algorithm in COMP3711 
- present the algorithm
  - provide unambigious description to the algorithm
  - minimize obvious technical details
  - remember it will be read by human. Make things stupidly clear
- Prove its correctnenss
  - give a high-level view and justification of the algorithm. 
  - after that, talks about some tricky elements of the algorithm
- Analyze its efficiency
  - give a worst-case analysis of the algorithm (the running time analysis) 
  - might have solve some recurrences/summation

## COMP3711
the very first lecture note named "mechanics" is about:
- [asymptotic analysis](../../../notes/asymptotic_analysis.md)  

the second lecture note named "Intro" is about:

- ### some sorting algorithms
  - [selection sort](../../../notes/selection_sort.md), it talks about:
    - the idea
    - pseudo-code
    - correctness proof
    - [running time analysis](../../../notes/runtime_analysis.md)
  - [insertion sort](../../../notes/insertion_sort.md)
    - the idea
    - pseudo-code
    - [running time analysis](../../../notes/runtime_analysis.md)
  - wild-guess sort (one page) (?)

- ### algorithm comparison
  - how to compare two algorithms:
    - what to measure?
      - **memory** (space complexity) (?)
      - total space (?)
      - working space (excluding the space for holding inputs) (?)
      - [running time](../../../notes/runtime_analysis.md)
    - how to measure?
      - **Empirical**: depends on actual implementations, computer hardware, etc. 
      - <u>**Analytical**</u>: depends only on the algorithm, focus of COMP3711, which is basically [this](../../../notes/runtime_analysis.md)
- ### analysis
  - best-case running time
    - an instance for a given size $n$ that results in the fastest possible running time 
    - Example: an already sorted array for [insertion sort](../../../notes/insertion_sort.md)
    - most of the time useless and not the focus of COMP3711
  - worst-case analysis
    - an instance for a given size $n$ that results in the slowest possible running time
    - Example: an inversely sortedd array for [insertion sort](../../../notes/insertion_sort.md)
  - Average case analysis
    - Running time averaged over all possible instances for the given size, assuming some probability distribution on the instances.
    - Example: for [insertion sort](../../../notes/insertion_sort.md), assuming that each of the $n!$ permutations of the $n$ numbers is equally likely
    - rigorous analysis can be complicated 
- ### More on worst-case analysis
  - The algorithm's worst case running time is $O(f(n))$  means:
    - On all inputs of (large) size $n$, the [running time](../../../notes/runtime_analysis.md) of the algorithm is $\leq c \cdot f(n)$
>   - It implies:
>     1. No need to find the worst input
>     2. No need to consider input size smaller than constant $n_0$ in the formal definition of [Big-O](../../../notes/big_O.md)
  - The algorithm's worst case running time is $\Omega(f(n))$
    - There exists at least one input of (large) size $n$ for which the running time of the algorithm is $\geq c \cdot f(n)$
>    - Mainly used to show that the big-O analysis is tight (i.e., the best possible upper bound)
>    - often not required

  - Example:  [insertion sort](../../../notes/insertion_sort.md)
    - On all inputs and worst input (in revser order), it requires $\frac{n(n - 1)}{2}$ time
    - Insertion sort runs in $O(n^2)$ time (upper bound) (worst-case)
    - Insertion sort runs in $\Omega(n^2)$ time (upper bound) (worst-case)
    - Therefore, Insertion sort runs in $\Theta(n^2)$ time 
    - Takeaway: once the [big-O](../../../notes/big_O.md) and [big-Omega](../../../notes/big_Omega.md) is the same. The bound is tight and we can conclude the corresponding function also applies to [big-Theta](../../../notes/big_Theta.md)
- ### When algorithms has the same theorical running time
  - how to distinnguish them?
    - closer examination of hidden constants
    - analysis of typical expected inputs 
    - other facts such as cache efficiency, parallelization, etc.
    - Empirical comparison 
  - theorical analysis provides first guidelines
    - useful when you do not know what input to expect
- ### pseudo-code 
  - talks about the importance of writing pseudo-code
    - makes the main idea more clear
  - how to write pseudo-code
    - use standard keywords like: (if/then/else, while, for, repeat/until, return) 
    - and notations like (<- for assigning variables, Array[index], func(arg)), etc.
    - Indent consistently, may also use `{}` for clarity
    - use standard maths notation instead of programming language 
      - `i = i + 1` instead of `i++`
      - $x \cdot y$ and $x \mod y$ instead of `x * y and x % y`
      - $\sqrt{x} and a^b$ instead of `sqrt(x)` and `power(a,b)`
    - use data structure as black boxes. If data structure is new, define its functionality first
    - Use standard/learned algorithm e.g. sorting as black boxes
      - e.g. sometimes just write "sort `A` in ascending order"
    - Use function to decompose complex algorithms
    - Use plain or natural language when it is clearer and simpler 
      - (e.g., if `A` is an array, you may write “`x` ← the maximum element in `A`”).
- ## And finally at the end of lecture note 1
  - ### [Exercise 2](../COMP3711/problems/COMP3711_problems/lecture1_exercise2.md)
  - ### [Exercise 3](../COMP3711/problems/COMP3711_problems/lecture1_exercise3.md)

# Lecture 2 DC (Divide and Conquer)
- Main idea: Solve a problem of size $n$ by breaking down the problem into smaller problem of size less than $n$
  - then solve the smaller problem recursively 
    - finally combine their solutions to solve the original problem which is large
- Example: [binary search](../../../notes/binary_search.md)

- More complex example: [Tower of Hanoi](../../../notes/tower_of_hanoi.md)
- [merge sort](../../../notes/merge_sort.md)


